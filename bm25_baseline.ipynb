{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python376jvsc74a57bd0724986c975149866732d61b2ac90a7d138756189efb080eae0ea097c9e5b0cee",
   "display_name": "Python 3.7.6 64-bit ('nlp-env': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "df = pickle.load(open(\"data/parsed_docs_with_toks.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filt = df.query(\"bd_news_flag != 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "idx = BM25Okapi(df_filt[\"tokens\"].tolist())\n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "\n",
    "pickle.dump(idx, open(\"saved_indices/bm250kapi_idx.pkl\", \"wb\"))\n",
    "print(\"finished\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "import re\n",
    "import swifter\n",
    "import pandas as pd  \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np \n",
    "\n",
    "def get_rank25_results(query: str, idx, num_results:int = 25):\n",
    "    scores = idx.get_scores(query)\n",
    "    sorted_score_idx = np.argsort(scores)[::-1]\n",
    "\n",
    "    results = {}\n",
    "    for i in sorted_score_idx[:num_results]:\n",
    "        docno = df.iloc[i][\"docno\"]\n",
    "        score = scores[i].item()\n",
    "        results[docno] = score\n",
    "    return results    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import read_qrel_from_file, evaluate_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrel = read_qrel_from_file(\"qrels/2020/cair2020_qrel.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "fp = open(\"qrels/2020/topics_test.txt\")\n",
    "soup = BeautifulSoup(fp, 'xml')\n",
    "soup.find_all(\"top\")\n",
    "\n",
    "extracted_topics = []\n",
    "for topic in soup.find_all(\"top\"):\n",
    "    number = str(topic.num.text)\n",
    "    title = topic.title.text.strip()\n",
    "    narr = topic.narr.text.strip()\n",
    "    extracted_topics.append({\"number\": number, \"title\": title, \"narrative\": narr})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   number                                              title  \\\n",
       "0       1                   Assassination of Osama-bin-laden   \n",
       "1       2                                Accused Ajmal Kasab   \n",
       "2       3            Maharashtra CM ashok chavan resignation   \n",
       "3       4                                Accused Sanjay Dutt   \n",
       "4       5                                  Abu Salem accused   \n",
       "5       6        Babri Masjid demolition case against Advani   \n",
       "6       7                        CBI searches Dawood Ibrahim   \n",
       "7       8                  Court blocks facebook in pakistan   \n",
       "8       9                          Jaswant Singh BJP sacking   \n",
       "9      10                      Kasab's nationality confirmed   \n",
       "10     11  Left Front withdraws support from the UPA Gove...   \n",
       "11     12                        Manu Sharma's life sentence   \n",
       "12     13                         Salman Khan sentenced jail   \n",
       "13     14                       Aftab Ansari sentenced death   \n",
       "14     15                   Rajya sabha sacked Jaya Bachchan   \n",
       "15     21                            Praveen Mahajan accused   \n",
       "16     22                        Lalu Prasad Yadav convicted   \n",
       "17     23                                   Mayawati accused   \n",
       "18     24                        Abdul Karim Telgi convicted   \n",
       "19     25           Protest against Narmada dam construction   \n",
       "\n",
       "                                            narrative  \n",
       "0   Relevant document should contain information a...  \n",
       "1   Information on Kasab's confession about 26/11 ...  \n",
       "2   Documents about Ashok Chavan's deliberate endi...  \n",
       "3   Relevant document would highlight that actor S...  \n",
       "4   Relevants documents will contain evidences on ...  \n",
       "5   A relevant document must include information a...  \n",
       "6   A relevant document must provide information r...  \n",
       "7   Relevant documents should contain information ...  \n",
       "8   Relevant documents should contain information ...  \n",
       "9   A relevant document must provide information o...  \n",
       "10  Relevant documents should contain information ...  \n",
       "11  Information related to the murder of the model...  \n",
       "12  Relevant documents will cite the arrest of Sal...  \n",
       "13  Any document that provides information related...  \n",
       "14  Jaya Bachchan has been disqualified from Rajya...  \n",
       "15  Relevant documents must contain information ab...  \n",
       "16  A relevant document should contain information...  \n",
       "17  A relevant document should focus on the invest...  \n",
       "18  Information regarding the arrest and suspensio...  \n",
       "19  Relevant documents must include information ab...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>number</th>\n      <th>title</th>\n      <th>narrative</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>Assassination of Osama-bin-laden</td>\n      <td>Relevant document should contain information a...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Accused Ajmal Kasab</td>\n      <td>Information on Kasab's confession about 26/11 ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>Maharashtra CM ashok chavan resignation</td>\n      <td>Documents about Ashok Chavan's deliberate endi...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>Accused Sanjay Dutt</td>\n      <td>Relevant document would highlight that actor S...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>Abu Salem accused</td>\n      <td>Relevants documents will contain evidences on ...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>Babri Masjid demolition case against Advani</td>\n      <td>A relevant document must include information a...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>CBI searches Dawood Ibrahim</td>\n      <td>A relevant document must provide information r...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>Court blocks facebook in pakistan</td>\n      <td>Relevant documents should contain information ...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>Jaswant Singh BJP sacking</td>\n      <td>Relevant documents should contain information ...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>Kasab's nationality confirmed</td>\n      <td>A relevant document must provide information o...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>11</td>\n      <td>Left Front withdraws support from the UPA Gove...</td>\n      <td>Relevant documents should contain information ...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>12</td>\n      <td>Manu Sharma's life sentence</td>\n      <td>Information related to the murder of the model...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>13</td>\n      <td>Salman Khan sentenced jail</td>\n      <td>Relevant documents will cite the arrest of Sal...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>14</td>\n      <td>Aftab Ansari sentenced death</td>\n      <td>Any document that provides information related...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>15</td>\n      <td>Rajya sabha sacked Jaya Bachchan</td>\n      <td>Jaya Bachchan has been disqualified from Rajya...</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>21</td>\n      <td>Praveen Mahajan accused</td>\n      <td>Relevant documents must contain information ab...</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>22</td>\n      <td>Lalu Prasad Yadav convicted</td>\n      <td>A relevant document should contain information...</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>23</td>\n      <td>Mayawati accused</td>\n      <td>A relevant document should focus on the invest...</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>24</td>\n      <td>Abdul Karim Telgi convicted</td>\n      <td>Information regarding the arrest and suspensio...</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>25</td>\n      <td>Protest against Narmada dam construction</td>\n      <td>Relevant documents must include information ab...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "def extract_topics_from_file(file: str) -> dict:\n",
    "    soup = BeautifulSoup(open(file, \"r\"), 'xml')\n",
    "\n",
    "    extracted_topics = []\n",
    "    for topic in soup.find_all(\"top\"):\n",
    "        number = str(topic.num.text)\n",
    "        title = topic.title.text.strip()\n",
    "        narr = topic.narr.text.strip()\n",
    "        extracted_topics.append({\"number\": number, \"title\": title, \"narrative\": narr})    \n",
    "    return pd.DataFrame(extracted_topics)\n",
    "\n",
    "topics = extract_topics_from_file(\"qrels/2020/topics_test.txt\")\n",
    "\n",
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytrec_eval\n",
    "metrics: set = {'map', 'ndcg', 'recall'}\n",
    "\n",
    "evaluator = pytrec_eval.RelevanceEvaluator(qrel, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"tok2vec\", \"ner\"])\n",
    "\n",
    "def preprocess_query(text):\n",
    "    clean_text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
    "    \n",
    "    toks = []\n",
    "    for tok in nlp(clean_text):\n",
    "        if tok.text not in STOP_WORDS and tok.text.strip() != \"\":\n",
    "            toks.append(tok.lemma_)\n",
    "    return toks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f21773e097704599b8255e16ca1faa8f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nfinished\n"
     ]
    }
   ],
   "source": [
    "import tqdm.notebook as tqdm\n",
    "import numpy as np\n",
    "title_run = {}\n",
    "narr_run = {}\n",
    "\n",
    "for topic in tqdm.tqdm(extracted_topics):\n",
    "    title_toks = preprocess_query(topic[\"title\"])\n",
    "    narr_toks = preprocess_query(topic[\"narrative\"])\n",
    "\n",
    "    title_results = get_rank25_results(title_toks, idx, 50)\n",
    "    narr_results = get_rank25_results(narr_toks, idx, 50)\n",
    "    \n",
    "    title_run[topic[\"number\"]] = title_results\n",
    "    narr_run[topic[\"number\"]] = narr_results\n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "{'1': {'map': 0.0002173913043478261, 'P_5': 0.0, 'ndcg': 0.00893619808537653},\n '2': {'map': 0.1259321200762225, 'P_5': 0.4, 'ndcg': 0.3328720689537768},\n '3': {'map': 0.22893544699514085, 'P_5': 0.2, 'ndcg': 0.5232275961284083},\n '4': {'map': 0.25274171815412877, 'P_5': 0.4, 'ndcg': 0.4739366864936738},\n '5': {'map': 0.4046342499193968, 'P_5': 0.8, 'ndcg': 0.5790681726821794},\n '6': {'map': 0.19284874240968863, 'P_5': 0.2, 'ndcg': 0.4362583005440685},\n '7': {'map': 0.30226092589700965, 'P_5': 0.8, 'ndcg': 0.5439887541679621},\n '8': {'map': 0.7347527472527473, 'P_5': 1.0, 'ndcg': 0.8495337194516893},\n '9': {'map': 0.16816772173308675, 'P_5': 0.6, 'ndcg': 0.37391337768044675},\n '10': {'map': 0.18606261894305373, 'P_5': 0.4, 'ndcg': 0.4037645750484759},\n '11': {'map': 0.11821294755705763, 'P_5': 0.4, 'ndcg': 0.27826340604050354},\n '12': {'map': 0.19652834072514383, 'P_5': 0.4, 'ndcg': 0.4521563559912647},\n '13': {'map': 0.46021409152712717, 'P_5': 1.0, 'ndcg': 0.6479221997264277},\n '14': {'map': 0.6200270657344824, 'P_5': 1.0, 'ndcg': 0.7737141319265843},\n '15': {'map': 0.2777100820848998, 'P_5': 0.4, 'ndcg': 0.49427774854742673},\n '21': {'map': 0.5999004955865007, 'P_5': 0.8, 'ndcg': 0.7654131333129602},\n '22': {'map': 0.014166666666666666, 'P_5': 0.2, 'ndcg': 0.08983022790869163},\n '23': {'map': 0.02236164736164736, 'P_5': 0.0, 'ndcg': 0.09546678525443415},\n '24': {'map': 0.373115899944084, 'P_5': 0.8, 'ndcg': 0.5666885084230826},\n '25': {'map': 0.49717273664709016, 'P_5': 0.8, 'ndcg': 0.7326175269349257}}"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Aggregate results\nAverage MAP:  0.28879818282597614\nAverage P_5:  0.53\n"
     ]
    }
   ],
   "source": [
    "import pytrec_eval\n",
    "import numpy as np \n",
    "import json \n",
    "\n",
    "metrics: set = {'map', 'ndcg', 'P_5'}\n",
    "\n",
    "evaluator = pytrec_eval.RelevanceEvaluator(qrel, metrics)\n",
    "run_results = evaluator.evaluate(title_run)\n",
    "\n",
    "map_scores = [v[\"map\"] for k,v in run_results.items()]\n",
    "p_scores  = [v[\"P_5\"] for k,v in run_results.items()]\n",
    "\n",
    "display(run_results)\n",
    "\n",
    "print(\"Aggregate results\")\n",
    "print(\"Average MAP: \", np.mean(map_scores))\n",
    "print(\"Average P_5: \", np.mean(p_scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "{'1': {'map': 0.0857992729838509, 'P_5': 0.4, 'ndcg': 0.24541403340349474},\n '2': {'map': 0.09291773146996271, 'P_5': 0.4, 'ndcg': 0.26489068160802665},\n '3': {'map': 0.21966240903604048, 'P_5': 0.2, 'ndcg': 0.5163460600226231},\n '4': {'map': 0.06638540431013955, 'P_5': 0.4, 'ndcg': 0.24807734635625595},\n '5': {'map': 0.4161339977285736, 'P_5': 1.0, 'ndcg': 0.5852790666091732},\n '6': {'map': 0.20315442597801556, 'P_5': 0.2, 'ndcg': 0.451153225278768},\n '7': {'map': 0.2505158547737754, 'P_5': 0.8, 'ndcg': 0.5015713626019195},\n '8': {'map': 0.45906334656334646, 'P_5': 0.4, 'ndcg': 0.7473829770969648},\n '9': {'map': 0.18853064242175385, 'P_5': 0.2, 'ndcg': 0.4168872426997385},\n '10': {'map': 0.08608322197031876, 'P_5': 0.4, 'ndcg': 0.2740905118763117},\n '11': {'map': 0.07576138370159298, 'P_5': 0.4, 'ndcg': 0.24505669724589946},\n '12': {'map': 0.40259024538508315, 'P_5': 0.6, 'ndcg': 0.6454313209816381},\n '13': {'map': 0.2676652326251622, 'P_5': 0.4, 'ndcg': 0.48800951596961595},\n '14': {'map': 0.5804208562048203, 'P_5': 1.0, 'ndcg': 0.7492456012511609},\n '15': {'map': 0.2917113844296141, 'P_5': 0.6, 'ndcg': 0.516096416876851},\n '21': {'map': 0.6081844112081541, 'P_5': 1.0, 'ndcg': 0.7743670291855008},\n '22': {'map': 0.012499999999999999, 'P_5': 0.2, 'ndcg': 0.086513904612645},\n '23': {'map': 0.00858819345661451, 'P_5': 0.0, 'ndcg': 0.0668452944447771},\n '24': {'map': 0.42079944496721783, 'P_5': 1.0, 'ndcg': 0.6067093337946636},\n '25': {'map': 0.38680564615210666, 'P_5': 0.4, 'ndcg': 0.6364068766273347}}"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Aggregate results\nAverage MAP:  0.2561636552683072\nAverage P_5:  0.4999999999999999\n"
     ]
    }
   ],
   "source": [
    "import pytrec_eval\n",
    "import numpy as np \n",
    "import json \n",
    "\n",
    "metrics: set = {'map', 'ndcg', 'P_5'}\n",
    "\n",
    "evaluator = pytrec_eval.RelevanceEvaluator(qrel, metrics)\n",
    "run_results = evaluator.evaluate(title_run)\n",
    "\n",
    "map_scores = [v[\"map\"] for k,v in run_results.items()]\n",
    "p_scores  = [v[\"P_5\"] for k,v in run_results.items()]\n",
    "\n",
    "display(run_results)\n",
    "\n",
    "print(\"Aggregate results\")\n",
    "print(\"Average MAP: \", np.mean(map_scores))\n",
    "print(\"Average P_5: \", np.mean(p_scores))\n",
    "\n",
    "# with open(\"results/bm250kap-baseline/title-results.txt\", \"w\") as f:\n",
    "#     f.write(f\"Average MAP: {np.mean(map_scores)}\\n\")\n",
    "#     f.write(f\"Average P_5: {np.mean(p_scores)}\\n\")\n",
    "#     f.write(f\"Individual run results: \\n\")\n",
    "#     f.write(json.dumps(run_results, indent=4))\n",
    "\n",
    "# with open(\"results/bm250kap-baseline/title-run.txt\", \"w\") as f:\n",
    "#     f.write(json.dumps(title_run, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "{'1': {'map': 0.05072817534200687, 'P_5': 0.4, 'ndcg': 0.18559757911380276},\n '2': {'map': 0.19134433607952664, 'P_5': 0.6, 'ndcg': 0.3890973191680332},\n '3': {'map': 0.7248846274136617, 'P_5': 1.0, 'ndcg': 0.9081052909699342},\n '4': {'map': 0.3041592311343593, 'P_5': 1.0, 'ndcg': 0.5069687016674774},\n '5': {'map': 0.2932776401822263, 'P_5': 1.0, 'ndcg': 0.473881032391106},\n '6': {'map': 0.25313361055164224, 'P_5': 0.6, 'ndcg': 0.5334326427178282},\n '7': {'map': 0.334377890247673, 'P_5': 0.8, 'ndcg': 0.5678092156120251},\n '8': {'map': 0.017151162790697675, 'P_5': 0.0, 'ndcg': 0.10974526590185513},\n '9': {'map': 0.5130935255369395, 'P_5': 0.6, 'ndcg': 0.7337893640575607},\n '10': {'map': 0.4753910086068267, 'P_5': 1.0, 'ndcg': 0.689388811610196},\n '11': {'map': 0.12167773609351289, 'P_5': 0.6, 'ndcg': 0.3086841437844016},\n '12': {'map': 0.38118848969212715, 'P_5': 0.4, 'ndcg': 0.6317121716627786},\n '13': {'map': 0.47794434367505584, 'P_5': 1.0, 'ndcg': 0.6439862076258248},\n '14': {'map': 0.22056619645292416, 'P_5': 0.6, 'ndcg': 0.44410148103343744},\n '15': {'map': 0.7999328613517476, 'P_5': 1.0, 'ndcg': 0.8936189272603108},\n '21': {'map': 0.6477378182493144, 'P_5': 1.0, 'ndcg': 0.7919994515435858},\n '22': {'map': 0.014740347893543383, 'P_5': 0.0, 'ndcg': 0.10005197912576921},\n '23': {'map': 0.5560280836842083, 'P_5': 0.6, 'ndcg': 0.7474838876731601},\n '24': {'map': 0.33974307590357783, 'P_5': 0.8, 'ndcg': 0.5507035210843299},\n '25': {'map': 0.3457432465332851, 'P_5': 0.6, 'ndcg': 0.6131951014849274}}"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Aggregate results\nAverage MAP:  0.3531421703707428\nAverage P_5:  0.6799999999999999\n"
     ]
    }
   ],
   "source": [
    "run_results = evaluator.evaluate(narr_run)\n",
    "\n",
    "map_scores = [v[\"map\"] for k,v in run_results.items()]\n",
    "p_scores  = [v[\"P_5\"] for k,v in run_results.items()]\n",
    "\n",
    "display(run_results)\n",
    "\n",
    "print(\"Aggregate results\")\n",
    "print(\"Average MAP: \", np.mean(map_scores))\n",
    "print(\"Average P_5: \", np.mean(p_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "{'1': {'map': 0.04402549433441882, 'P_5': 0.4, 'ndcg': 0.17227327297591483},\n '2': {'map': 0.1868069134882157, 'P_5': 0.6, 'ndcg': 0.3866051581702334},\n '3': {'map': 0.7272447414197384, 'P_5': 1.0, 'ndcg': 0.9088433466673372},\n '4': {'map': 0.31381425763566484, 'P_5': 1.0, 'ndcg': 0.5202545637719598},\n '5': {'map': 0.28162893887628765, 'P_5': 1.0, 'ndcg': 0.46215507858247157},\n '6': {'map': 0.24250418514395317, 'P_5': 0.6, 'ndcg': 0.5136410432069678},\n '7': {'map': 0.268405442651054, 'P_5': 0.8, 'ndcg': 0.49828958478148627},\n '8': {'map': 0.0047619047619047615, 'P_5': 0.0, 'ndcg': 0.04935421935348238},\n '9': {'map': 0.4642077787980886, 'P_5': 0.4, 'ndcg': 0.6835174615774817},\n '10': {'map': 0.44197706381403146, 'P_5': 1.0, 'ndcg': 0.6589136441994532},\n '11': {'map': 0.07705919166748026, 'P_5': 0.6, 'ndcg': 0.24716036726857735},\n '12': {'map': 0.3827854210316024, 'P_5': 0.4, 'ndcg': 0.6323273456684958},\n '13': {'map': 0.27428235399992373, 'P_5': 0.2, 'ndcg': 0.4639665499009099},\n '14': {'map': 0.21772329374160035, 'P_5': 0.6, 'ndcg': 0.4426742619474174},\n '15': {'map': 0.7796549111706913, 'P_5': 1.0, 'ndcg': 0.8761344676851893},\n '21': {'map': 0.6478033262531098, 'P_5': 1.0, 'ndcg': 0.7919391675033607},\n '22': {'map': 0.011147660818713451, 'P_5': 0.0, 'ndcg': 0.07954840547373838},\n '23': {'map': 0.5604698178875207, 'P_5': 0.6, 'ndcg': 0.7539903853555809},\n '24': {'map': 0.3417927887582703, 'P_5': 0.8, 'ndcg': 0.55206605459192},\n '25': {'map': 0.22978773700275348, 'P_5': 0.4, 'ndcg': 0.4908327783047249}}"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Aggregate results\nAverage MAP:  0.32489416116275116\nAverage P_5:  0.62\n"
     ]
    }
   ],
   "source": [
    "run_results = evaluator.evaluate(narr_run)\n",
    "\n",
    "map_scores = [v[\"map\"] for k,v in run_results.items()]\n",
    "p_scores  = [v[\"P_5\"] for k,v in run_results.items()]\n",
    "\n",
    "display(run_results)\n",
    "\n",
    "print(\"Aggregate results\")\n",
    "print(\"Average MAP: \", np.mean(map_scores))\n",
    "print(\"Average P_5: \", np.mean(p_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "{'1': {'map': 0.24554547962813247, 'P_5': 1.0, 'ndcg': 0.43195244767143376},\n '2': {'map': 0.09316836010136732, 'P_5': 0.2, 'ndcg': 0.26286249092777214},\n '3': {'map': 0.6781836591938896, 'P_5': 1.0, 'ndcg': 0.8419504708828816},\n '4': {'map': 0.20881728355238408, 'P_5': 0.6, 'ndcg': 0.39788740206231976},\n '5': {'map': 0.30906608872874, 'P_5': 1.0, 'ndcg': 0.49363714531501374},\n '6': {'map': 0.21590003848037764, 'P_5': 0.8, 'ndcg': 0.46805865253277174},\n '7': {'map': 0.22486683527503215, 'P_5': 0.8, 'ndcg': 0.4615856394639282},\n '8': {'map': 0.025, 'P_5': 0.2, 'ndcg': 0.09478836436955078},\n '9': {'map': 0.49343012855076335, 'P_5': 0.6, 'ndcg': 0.7221873256895347},\n '10': {'map': 0.46085418124891814, 'P_5': 1.0, 'ndcg': 0.6665286161517171},\n '11': {'map': 0.03805272719690148, 'P_5': 0.0, 'ndcg': 0.15358268625049804},\n '12': {'map': 0.48891263513879235, 'P_5': 0.8, 'ndcg': 0.7262392552464187},\n '13': {'map': 0.24857027763549955, 'P_5': 0.4, 'ndcg': 0.45001064894167886},\n '14': {'map': 0.20925381475531796, 'P_5': 0.6, 'ndcg': 0.4163887882573837},\n '15': {'map': 0.6719883240989313, 'P_5': 1.0, 'ndcg': 0.8225237165722794},\n '21': {'map': 0.7356979341497722, 'P_5': 1.0, 'ndcg': 0.8252840392744833},\n '22': {'map': 0.023163527037255067, 'P_5': 0.2, 'ndcg': 0.12668417677174526},\n '23': {'map': 0.5629587871434385, 'P_5': 0.6, 'ndcg': 0.7498254302903895},\n '24': {'map': 0.3369402500789714, 'P_5': 0.8, 'ndcg': 0.5477696104061823},\n '25': {'map': 0.30034452779794396, 'P_5': 0.2, 'ndcg': 0.5037212547207174}}"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Aggregate results\nAverage MAP:  0.3285357429896214\nAverage P_5:  0.6399999999999999\n"
     ]
    }
   ],
   "source": [
    "run_results = evaluator.evaluate(narr_run)\n",
    "\n",
    "map_scores = [v[\"map\"] for k,v in run_results.items()]\n",
    "p_scores  = [v[\"P_5\"] for k,v in run_results.items()]\n",
    "\n",
    "display(run_results)\n",
    "\n",
    "print(\"Aggregate results\")\n",
    "print(\"Average MAP: \", np.mean(map_scores))\n",
    "print(\"Average P_5: \", np.mean(p_scores))\n",
    "\n",
    "with open(\"results/bm250kap-baseline/narrative-results.txt\", \"w\") as f:\n",
    "    f.write(f\"Average MAP: {np.mean(map_scores)}\\n\")\n",
    "    f.write(f\"Average P_5: {np.mean(p_scores)}\\n\")\n",
    "    f.write(f\"Individual run results: \\n\")\n",
    "    f.write(json.dumps(run_results, indent=4))\n",
    "\n",
    "with open(\"results/bm250kap-baseline/narrative-run.txt\", \"w\") as f:\n",
    "    f.write(json.dumps(title_run, indent=4))"
   ]
  }
 ]
}