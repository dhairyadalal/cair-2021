{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python382jvsc74a57bd0ae33fd632762133c8e3fb8323231e5047482a99a5084595a47cef341a740e680",
   "display_name": "Python 3.8.2 64-bit ('deeplearning': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import compress_pickle\n",
    "\n",
    "df = compress_pickle.load( \"parsed_docs_lemmas.pkl.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "idx = BM25Okapi(df[\"processed_text\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "pickle.dump(idx, open(\"saved_indices/bm250kapi_idx.pkl\", \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"Telecom minister A. Raja resignation\"\n",
    "q = [tok.lower() for tok in q.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "num_results = 100\n",
    "\n",
    "def get_rank25_results(query: str, idx, num_results:int = 25):\n",
    "    scores = idx.get_scores(query)\n",
    "    sorted_score_idx = np.argsort(scores)[::-1]\n",
    "\n",
    "    results = {}\n",
    "    for i in sorted_score_idx[:num_results]:\n",
    "        docno = df.iloc[i][\"docno\"]\n",
    "        score = scores[i].item()\n",
    "        results[docno] = score\n",
    "    return results    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import read_qrel_from_file, evaluate_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrel = read_qrel_from_file(\"qrels/2020/cair2020_qrel.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "fp = open(\"qrels/2020/topics_test.txt\")\n",
    "soup = BeautifulSoup(fp, 'xml')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_topics_from_file(file: str) -> dict:\n",
    "    soup = BeautifulSoup(open(file, \"r\"), 'xml')\n",
    "\n",
    "    extracted_topics = []\n",
    "    for topic in soup.find_all(\"top\"):\n",
    "        number = str(topic.num.text)\n",
    "        title = topic.title.text\n",
    "        narr = topic.narr.text\n",
    "        extracted_topics.append({\"number\": number, \"title\": title, \"narrative\": narr})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'16': {'map': 0.21088205472964247,\n",
       "  'recall_5': 0.058823529411764705,\n",
       "  'recall_10': 0.11764705882352941,\n",
       "  'recall_15': 0.14705882352941177,\n",
       "  'recall_20': 0.17647058823529413,\n",
       "  'recall_30': 0.23529411764705882,\n",
       "  'recall_100': 0.5882352941176471,\n",
       "  'recall_200': 0.5882352941176471,\n",
       "  'recall_500': 0.5882352941176471,\n",
       "  'recall_1000': 0.5882352941176471,\n",
       "  'ndcg': 0.526916034973694}}"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "import pytrec_eval\n",
    "metrics: set = {'map', 'ndcg', 'recall'}\n",
    "\n",
    "evaluator = pytrec_eval.RelevanceEvaluator(qrel, metrics)\n",
    "evaluator.evaluate(run)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en', disable=[\"tagger\", \"ner\", \"parser\"])\n",
    "\n",
    "def preprocess_query(text):\n",
    "    cleaned_query = []\n",
    "    for tok in nlp(text):\n",
    "        tok = tok.lemma_.lower()\n",
    "        if tok.isalpha():\n",
    "            cleaned_query.append(tok)\n",
    "    return cleaned_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3de00da4cfde44dcb5075f0fb8542b93"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "import tqdm.notebook as tqdm\n",
    "title_run = {}\n",
    "narr_run = {}\n",
    "\n",
    "for topic in tqdm.tqdm(extracted_topics):\n",
    "    title_toks = preprocess_query(topic[\"title\"])\n",
    "    narr_toks = preprocess_query(topic[\"narrative\"])\n",
    "\n",
    "    title_results = get_rank25_results(title_toks, idx, 50)\n",
    "    narr_results = get_rank25_results(narr_toks, idx, 50)\n",
    "    \n",
    "    title_run[topic[\"number\"]] = title_results\n",
    "    narr_run[topic[\"number\"]] = narr_results\n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "{'1': {'map': 0.0857992729838509, 'P_5': 0.4, 'ndcg': 0.24541403340349474},\n '2': {'map': 0.09291773146996271, 'P_5': 0.4, 'ndcg': 0.26489068160802665},\n '3': {'map': 0.21966240903604048, 'P_5': 0.2, 'ndcg': 0.5163460600226231},\n '4': {'map': 0.06638540431013955, 'P_5': 0.4, 'ndcg': 0.24807734635625595},\n '5': {'map': 0.4161339977285736, 'P_5': 1.0, 'ndcg': 0.5852790666091732},\n '6': {'map': 0.20315442597801556, 'P_5': 0.2, 'ndcg': 0.451153225278768},\n '7': {'map': 0.2505158547737754, 'P_5': 0.8, 'ndcg': 0.5015713626019195},\n '8': {'map': 0.45906334656334646, 'P_5': 0.4, 'ndcg': 0.7473829770969648},\n '9': {'map': 0.18853064242175385, 'P_5': 0.2, 'ndcg': 0.4168872426997385},\n '10': {'map': 0.08608322197031876, 'P_5': 0.4, 'ndcg': 0.2740905118763117},\n '11': {'map': 0.07576138370159298, 'P_5': 0.4, 'ndcg': 0.24505669724589946},\n '12': {'map': 0.40259024538508315, 'P_5': 0.6, 'ndcg': 0.6454313209816381},\n '13': {'map': 0.2676652326251622, 'P_5': 0.4, 'ndcg': 0.48800951596961595},\n '14': {'map': 0.5804208562048203, 'P_5': 1.0, 'ndcg': 0.7492456012511609},\n '15': {'map': 0.2917113844296141, 'P_5': 0.6, 'ndcg': 0.516096416876851},\n '21': {'map': 0.6081844112081541, 'P_5': 1.0, 'ndcg': 0.7743670291855008},\n '22': {'map': 0.012499999999999999, 'P_5': 0.2, 'ndcg': 0.086513904612645},\n '23': {'map': 0.00858819345661451, 'P_5': 0.0, 'ndcg': 0.0668452944447771},\n '24': {'map': 0.42079944496721783, 'P_5': 1.0, 'ndcg': 0.6067093337946636},\n '25': {'map': 0.38680564615210666, 'P_5': 0.4, 'ndcg': 0.6364068766273347}}"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Aggregate results\nAverage MAP:  0.2561636552683072\nAverage P_5:  0.4999999999999999\n"
     ]
    }
   ],
   "source": [
    "import pytrec_eval\n",
    "import numpy as np \n",
    "import json \n",
    "\n",
    "metrics: set = {'map', 'ndcg', 'P_5'}\n",
    "\n",
    "evaluator = pytrec_eval.RelevanceEvaluator(qrel, metrics)\n",
    "run_results = evaluator.evaluate(title_run)\n",
    "\n",
    "map_scores = [v[\"map\"] for k,v in run_results.items()]\n",
    "p_scores  = [v[\"P_5\"] for k,v in run_results.items()]\n",
    "\n",
    "display(run_results)\n",
    "\n",
    "print(\"Aggregate results\")\n",
    "print(\"Average MAP: \", np.mean(map_scores))\n",
    "print(\"Average P_5: \", np.mean(p_scores))\n",
    "\n",
    "with open(\"results/bm250kap-baseline/title-results.txt\", \"w\") as f:\n",
    "    f.write(f\"Average MAP: {np.mean(map_scores)}\\n\")\n",
    "    f.write(f\"Average P_5: {np.mean(p_scores)}\\n\")\n",
    "    f.write(f\"Individual run results: \\n\")\n",
    "    f.write(json.dumps(run_results, indent=4))\n",
    "\n",
    "with open(\"results/bm250kap-baseline/title-run.txt\", \"w\") as f:\n",
    "    f.write(json.dumps(title_run, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{\n    \"1\": {\n        \"map\": 0.24554547962813247,\n        \"P_5\": 1.0,\n        \"ndcg\": 0.43195244767143376\n    },\n    \"2\": {\n        \"map\": 0.09316836010136732,\n        \"P_5\": 0.2,\n        \"ndcg\": 0.26286249092777214\n    },\n    \"3\": {\n        \"map\": 0.6781836591938896,\n        \"P_5\": 1.0,\n        \"ndcg\": 0.8419504708828816\n    },\n    \"4\": {\n        \"map\": 0.20881728355238408,\n        \"P_5\": 0.6,\n        \"ndcg\": 0.39788740206231976\n    },\n    \"5\": {\n        \"map\": 0.30906608872874,\n        \"P_5\": 1.0,\n        \"ndcg\": 0.49363714531501374\n    },\n    \"6\": {\n        \"map\": 0.21590003848037764,\n        \"P_5\": 0.8,\n        \"ndcg\": 0.46805865253277174\n    },\n    \"7\": {\n        \"map\": 0.22486683527503215,\n        \"P_5\": 0.8,\n        \"ndcg\": 0.4615856394639282\n    },\n    \"8\": {\n        \"map\": 0.025,\n        \"P_5\": 0.2,\n        \"ndcg\": 0.09478836436955078\n    },\n    \"9\": {\n        \"map\": 0.49343012855076335,\n        \"P_5\": 0.6,\n        \"ndcg\": 0.7221873256895347\n    },\n    \"10\": {\n        \"map\": 0.46085418124891814,\n        \"P_5\": 1.0,\n        \"ndcg\": 0.6665286161517171\n    },\n    \"11\": {\n        \"map\": 0.03805272719690148,\n        \"P_5\": 0.0,\n        \"ndcg\": 0.15358268625049804\n    },\n    \"12\": {\n        \"map\": 0.48891263513879235,\n        \"P_5\": 0.8,\n        \"ndcg\": 0.7262392552464187\n    },\n    \"13\": {\n        \"map\": 0.24857027763549955,\n        \"P_5\": 0.4,\n        \"ndcg\": 0.45001064894167886\n    },\n    \"14\": {\n        \"map\": 0.20925381475531796,\n        \"P_5\": 0.6,\n        \"ndcg\": 0.4163887882573837\n    },\n    \"15\": {\n        \"map\": 0.6719883240989313,\n        \"P_5\": 1.0,\n        \"ndcg\": 0.8225237165722794\n    },\n    \"21\": {\n        \"map\": 0.7356979341497722,\n        \"P_5\": 1.0,\n        \"ndcg\": 0.8252840392744833\n    },\n    \"22\": {\n        \"map\": 0.023163527037255067,\n        \"P_5\": 0.2,\n        \"ndcg\": 0.12668417677174526\n    },\n    \"23\": {\n        \"map\": 0.5629587871434385,\n        \"P_5\": 0.6,\n        \"ndcg\": 0.7498254302903895\n    },\n    \"24\": {\n        \"map\": 0.3369402500789714,\n        \"P_5\": 0.8,\n        \"ndcg\": 0.5477696104061823\n    },\n    \"25\": {\n        \"map\": 0.30034452779794396,\n        \"P_5\": 0.2,\n        \"ndcg\": 0.5037212547207174\n    }\n}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "print(json.dumps(run_results, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "{'1': {'map': 0.24554547962813247, 'P_5': 1.0, 'ndcg': 0.43195244767143376},\n '2': {'map': 0.09316836010136732, 'P_5': 0.2, 'ndcg': 0.26286249092777214},\n '3': {'map': 0.6781836591938896, 'P_5': 1.0, 'ndcg': 0.8419504708828816},\n '4': {'map': 0.20881728355238408, 'P_5': 0.6, 'ndcg': 0.39788740206231976},\n '5': {'map': 0.30906608872874, 'P_5': 1.0, 'ndcg': 0.49363714531501374},\n '6': {'map': 0.21590003848037764, 'P_5': 0.8, 'ndcg': 0.46805865253277174},\n '7': {'map': 0.22486683527503215, 'P_5': 0.8, 'ndcg': 0.4615856394639282},\n '8': {'map': 0.025, 'P_5': 0.2, 'ndcg': 0.09478836436955078},\n '9': {'map': 0.49343012855076335, 'P_5': 0.6, 'ndcg': 0.7221873256895347},\n '10': {'map': 0.46085418124891814, 'P_5': 1.0, 'ndcg': 0.6665286161517171},\n '11': {'map': 0.03805272719690148, 'P_5': 0.0, 'ndcg': 0.15358268625049804},\n '12': {'map': 0.48891263513879235, 'P_5': 0.8, 'ndcg': 0.7262392552464187},\n '13': {'map': 0.24857027763549955, 'P_5': 0.4, 'ndcg': 0.45001064894167886},\n '14': {'map': 0.20925381475531796, 'P_5': 0.6, 'ndcg': 0.4163887882573837},\n '15': {'map': 0.6719883240989313, 'P_5': 1.0, 'ndcg': 0.8225237165722794},\n '21': {'map': 0.7356979341497722, 'P_5': 1.0, 'ndcg': 0.8252840392744833},\n '22': {'map': 0.023163527037255067, 'P_5': 0.2, 'ndcg': 0.12668417677174526},\n '23': {'map': 0.5629587871434385, 'P_5': 0.6, 'ndcg': 0.7498254302903895},\n '24': {'map': 0.3369402500789714, 'P_5': 0.8, 'ndcg': 0.5477696104061823},\n '25': {'map': 0.30034452779794396, 'P_5': 0.2, 'ndcg': 0.5037212547207174}}"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Aggregate results\nAverage MAP:  0.3285357429896214\nAverage P_5:  0.6399999999999999\n"
     ]
    }
   ],
   "source": [
    "run_results = evaluator.evaluate(narr_run)\n",
    "\n",
    "map_scores = [v[\"map\"] for k,v in run_results.items()]\n",
    "p_scores  = [v[\"P_5\"] for k,v in run_results.items()]\n",
    "\n",
    "display(run_results)\n",
    "\n",
    "print(\"Aggregate results\")\n",
    "print(\"Average MAP: \", np.mean(map_scores))\n",
    "print(\"Average P_5: \", np.mean(p_scores))\n",
    "\n",
    "with open(\"results/bm250kap-baseline/narrative-results.txt\", \"w\") as f:\n",
    "    f.write(f\"Average MAP: {np.mean(map_scores)}\\n\")\n",
    "    f.write(f\"Average P_5: {np.mean(p_scores)}\\n\")\n",
    "    f.write(f\"Individual run results: \\n\")\n",
    "    f.write(json.dumps(run_results, indent=4))\n",
    "\n",
    "with open(\"results/bm250kap-baseline/narrative-run.txt\", \"w\") as f:\n",
    "    f.write(json.dumps(title_run, indent=4))"
   ]
  }
 ]
}